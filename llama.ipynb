{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-25T20:00:49.236687Z",
     "start_time": "2025-01-25T20:00:16.666225Z"
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
    "from unsloth import is_bfloat16_supported\n",
    "from unsloth import FastLanguageModel\n",
    "from unsloth.chat_templates import train_on_responses_only\n",
    "import torch\n",
    "\n",
    "src_model = \"unsloth/Llama-3.2-3B-Instruct\"\n",
    "new_model = \"Llama-3.2-3B-trained\"\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = src_model,\n",
    "    max_seq_length = 2048,\n",
    "    dtype = None,\n",
    "    load_in_4bit = True,\n",
    ")\n",
    "\n",
    "dataset = load_dataset('csv', data_files='./train_cases.csv')\n",
    "\n",
    "def format_chat_template(row):\n",
    "\n",
    "    row_json = [\n",
    "               {\"role\": \"user\", \"content\": row[\"Context\"]},\n",
    "               {\"role\": \"assistant\", \"content\": row[\"Response\"]}\n",
    "               ]\n",
    "\n",
    "    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n",
    "    return row\n",
    "\n",
    "dataset = dataset[\"train\"].map(\n",
    "    format_chat_template,\n",
    "    num_proc= 4,\n",
    ")\n",
    "\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,\n",
    "    loftq_config = None,\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = 2048,\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size=2,\n",
    "        per_device_eval_batch_size=2,\n",
    "        gradient_accumulation_steps=4,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=0.2,\n",
    "        warmup_steps = 5,\n",
    "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        max_steps = 60,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"model_traning_outputs\",\n",
    "        report_to = \"none\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
    "    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
    ")\n",
    "\n",
    "trainer_stats = trainer.train()\n",
    "\n",
    "print( trainer_stats )\n",
    "\n",
    "model.save_pretrained(new_model)\n",
    "tokenizer.save_pretrained(new_model)"
   ],
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Unsloth: No NVIDIA GPU found? Unsloth currently only supports GPUs!",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtrl\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SFTTrainer\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TrainingArguments, DataCollatorForSeq2Seq\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01munsloth\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m is_bfloat16_supported\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01munsloth\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FastLanguageModel\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01munsloth\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mchat_templates\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train_on_responses_only\n",
      "File \u001B[1;32m~\\TG_code\\venv\\Lib\\site-packages\\unsloth\\__init__.py:91\u001B[0m\n\u001B[0;32m     89\u001B[0m \u001B[38;5;66;03m# First check if CUDA is available ie a NVIDIA GPU is seen\u001B[39;00m\n\u001B[0;32m     90\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available():\n\u001B[1;32m---> 91\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnsloth: No NVIDIA GPU found? Unsloth currently only supports GPUs!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     93\u001B[0m \u001B[38;5;66;03m# Fix Xformers performance issues since 0.0.25\u001B[39;00m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mimportlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m\n",
      "\u001B[1;31mNotImplementedError\u001B[0m: Unsloth: No NVIDIA GPU found? Unsloth currently only supports GPUs!"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1a4af3282c513a89"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
